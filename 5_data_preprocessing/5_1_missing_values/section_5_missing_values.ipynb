{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "\n",
    "In this section, we'll be learning different missing value imputation techniques by analyzing simulated customer lifetime value data. Customer Lifetime Value is the total monetary worth the customer has to the business, over the course of its business-customer relationship. In this dataset, to keep things simple, we'll be using purchases as a proxy for CLV. \n",
    "\n",
    "We'll be covering how to:\n",
    "\n",
    "- Check the number of null values\n",
    "\n",
    "- Dropping Null Values\n",
    "\n",
    "- Mean/Median/Mode Imputation\n",
    "\n",
    "- Multiple Imputation using Regression\n",
    "\n",
    "- Imputation using Nearest Neighbors\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## Import Libraries\n",
    "\n",
    "First, we'll need to import the relevant libraries. We'll be using the standard `pandas`, `numpy` libraries for data manipulation. We'll then be using `sklearn` for the more advanced imputation techniques. We will use `scipy` for the `mode` imputation later on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MCAR : Missing completely as random , PROBA OF DATA BEING MISSING IS THE SAME FOR ALL OBS. completely random loss of data : System breaks or... (drop them )\n",
    "- MAR : missing by observed data Missing at random, data is missing because of the actual data missing values have a patterns in the data (impute, create a dummy variable ?)\n",
    "- MNAR : Not : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Next, we'll load our customer lifetime value dataset. You'll see in our dataset, we have about 6 columns. The `purchases` column is the column we care about in our customer lifetime value problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>days_on_platform</th>\n",
       "      <th>city</th>\n",
       "      <th>purchases</th>\n",
       "      <th>lifetime_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>126895</td>\n",
       "      <td>14.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>161474</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>104723</td>\n",
       "      <td>34.0</td>\n",
       "      <td>London</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>43791</td>\n",
       "      <td>28.0</td>\n",
       "      <td>London</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>132181</td>\n",
       "      <td>26.0</td>\n",
       "      <td>London</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id   age  gender  income  days_on_platform           city  \\\n",
       "0           0   0   NaN    Male  126895              14.0  San Francisco   \n",
       "1           1   1   NaN    Male  161474              14.0          Tokyo   \n",
       "2           2   2  24.0    Male  104723              34.0         London   \n",
       "3           3   3  29.0    Male   43791              28.0         London   \n",
       "4           4   4  18.0  Female  132181              26.0         London   \n",
       "\n",
       "   purchases  lifetime_value  \n",
       "0          0               0  \n",
       "1          0               0  \n",
       "2          1              20  \n",
       "3          2              40  \n",
       "4          2              40  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\RAZER BLADE\\OneDrive\\Bureau\\Python\\ML_Process_Course-main\\5_data_preprocessing\\5_1_missing_values\\clv_data.csv\")\n",
    "print(df.shape)\n",
    "df['lifetime_value'] = df['purchases'] * 20\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(5,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Null Values\n",
    "\n",
    "The first step in any data analysis or ML model is to check null values. We can check the number of nulls in a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             0\n",
       "id                     0\n",
       "age                 2446\n",
       "gender                 0\n",
       "income                 0\n",
       "days_on_platform     141\n",
       "city                   0\n",
       "purchases              0\n",
       "lifetime_value         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you want to see the percentages, we wrote a function you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_count</th>\n",
       "      <th>null_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>2446</td>\n",
       "      <td>0.4892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_on_platform</th>\n",
       "      <td>141</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchases</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lifetime_value</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  null_count  null_pct\n",
       "Unnamed: 0                 0    0.0000\n",
       "id                         0    0.0000\n",
       "age                     2446    0.4892\n",
       "gender                     0    0.0000\n",
       "income                     0    0.0000\n",
       "days_on_platform         141    0.0282\n",
       "city                       0    0.0000\n",
       "purchases                  0    0.0000\n",
       "lifetime_value             0    0.0000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nulls_summary_table(df):\n",
    "    \"\"\"\n",
    "    Returns a summary table showing null value counts and percentage\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Dataframe to check\n",
    "    \n",
    "    Returns:\n",
    "    null_values (DataFrame)\n",
    "    \"\"\"\n",
    "    null_values = pd.DataFrame(df.isnull().sum())\n",
    "    null_values[1] = null_values[0]/len(df)\n",
    "    null_values.columns = ['null_count','null_pct']\n",
    "    return null_values\n",
    "\n",
    "nulls_summary_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Null Values\n",
    "\n",
    "Dropping nulls is the quickest and easiest method to dropping nulls. We will use the internal pandas method `dropna` which will simply drop all rows that contain nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2476, 9) (5000, 9)\n"
     ]
    }
   ],
   "source": [
    "drop_df = df.copy()\n",
    "\n",
    "# drop_df = drop_df.dropna()\n",
    "\n",
    "drop_df.dropna(inplace=True)\n",
    "\n",
    "print(drop_df.shape, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2104, 3)\n",
      "(372, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_d = drop_df[['age','days_on_platform','income']]\n",
    "y_d = drop_df['lifetime_value']\n",
    "\n",
    "\n",
    "X_train_d, X_test_d, y_train_d , y_test_d =  train_test_split(X_d, y_d, test_size=0.15, random_state=0)\n",
    "\n",
    "print(X_train_d.shape)\n",
    "print(X_test_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>days_on_platform</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>104723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>43791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>132181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>46.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>129157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>75425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>47.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>84987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>33.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>36.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>88858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2476 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  days_on_platform  income\n",
       "2     24.0              34.0  104723\n",
       "3     29.0              28.0   43791\n",
       "4     18.0              26.0  132181\n",
       "5     23.0              14.0   12315\n",
       "8     46.0              23.0  129157\n",
       "...    ...               ...     ...\n",
       "4986  23.0               6.0   75425\n",
       "4989  47.0              30.0   84987\n",
       "4990  33.0              89.0    3020\n",
       "4991  36.0              34.0   26173\n",
       "4992  26.0              14.0   88858\n",
       "\n",
       "[2476 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it works even table has only 2k rows\n",
    "X_d[:1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean/Median/Mode Imputation\n",
    "\n",
    "The next is mean/median/mode imputation. We can use the native numpy functions for the mean and median. We can use scipy for the mode. Then, pandas as a native `fillna` method we can use to impute the nulls with the mean/median/mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4250, 3)\n"
     ]
    }
   ],
   "source": [
    "m_df = df.copy()\n",
    "\n",
    "X_m = m_df[['age','days_on_platform','income']]\n",
    "y_m = m_df['lifetime_value']\n",
    "\n",
    "\n",
    "X_train_m, X_test_m, y_train_m , y_test_m =  train_test_split(X_m, y_m, test_size=0.15, random_state=0)\n",
    "print(X_train_m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use train mean on test data\n",
    "X_train_m.loc[:,'age'] = X_train_m['age'].fillna(np.mean(X_train_m['age']))\n",
    "X_test_m.loc[:,'age'] = X_test_m['age'].fillna(np.mean(X_train_m['age'])) ## Cannot use test dataset to impute\n",
    "\n",
    "\n",
    "X_train_m.loc[:,'days_on_platform'] = X_train_m['days_on_platform'].fillna(np.mean(X_train_m['days_on_platform']))\n",
    "X_test_m.loc[:,'days_on_platform'] = X_test_m['days_on_platform'].fillna(np.mean(X_train_m['days_on_platform'])) ## Cannot use training dataset to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Median\n",
    "m_df.loc[:,'age'] = df['age'].fillna(np.median(m_df['age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mode\n",
    "m_df.loc[:,'age'] = m_df['age'].fillna(stats.mode(m_df['age'])[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Imputation Using Regression\n",
    "\n",
    "Now that we've covered the simpler imputation techniques, we'll cover a more complicated imputation technique: Multiple Imputation. Multiple Imputation requires you to have some knowledge of ML modeling because we are using an ML model to impute the missing values. We won't go over every argument, but we'll go over the key ones. \n",
    "\n",
    "Multiple imputation has a few different estimators, using the `estimator` argument:\n",
    "\n",
    "- `BayesianRidge`: Regularized Linear Regression\n",
    "\n",
    "- `RandomForestRegressor`: Random Forest Model. Mimics missForest in the R language.\n",
    "\n",
    "We'll go over how these estimators work in the next course: ML Algorithms. \n",
    "\n",
    "The `missing_values` argument is a placeholder for the data type of the missing values you want to impute. \n",
    "\n",
    "It's important to use `add_indicatorbool` as it'll create a placeholder indicating that you've imputed a missing value. This is important, because there could be patterns behind how a value is missing. Adding an indicator would allow you to keep track of where you made an imputation. Plus, it could also add signal into your model. \n",
    "\n",
    "`max_iter`: The number of iteration rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "days_on_platform    0\n",
       "income              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "## Target - Purchases in the first six months\n",
    "\n",
    "r_df = df.copy()\n",
    "\n",
    "X_r = r_df[['age','days_on_platform','income']]\n",
    "y_r = r_df['lifetime_value']\n",
    "\n",
    "\n",
    "X_train_r = X_r[:4000]\n",
    "y_train_r = y_r[:4000]\n",
    "\n",
    "X_test_r = X_r[1000:]\n",
    "y_test_r = y_r[1000:]\n",
    "\n",
    "\n",
    "Imp = IterativeImputer(estimator=LinearRegression(), max_iter=10, random_state = 0)\n",
    "Imp.fit(X_train_r)\n",
    "\n",
    "X_train_r = Imp.transform(X_train_r)\n",
    "X_test_r = Imp.transform(X_test_r)\n",
    "\n",
    "X_train_r = pd.DataFrame(X_train_r)\n",
    "X_train_r.columns = X_r.columns\n",
    "\n",
    "X_test_r = pd.DataFrame(X_test_r)\n",
    "X_test_r.columns = X_r.columns\n",
    "\n",
    "r_df = pd.concat([X_train_r, X_test_r], axis = 0)\n",
    "r_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor Imputation\n",
    "\n",
    "On top of using linear regression or random forest regression to impute values, you can also use nearest neighbors imputation. Nearest neighbor imputation essentially uses a K-Nearest Neighbors algorithm to find the most similar data points, to impute the null values. \n",
    "\n",
    "**Important Parameters**\n",
    "\n",
    "`missing_values`: This is the type of null value you want to impute. Typically, this is NaN, but it could be float or whichever you decide. \n",
    "\n",
    "`n_neighbors`: The number of neighbors to use for imputation. You can add more or less. Fewer neighbors can lead to overfitting. Larger numbers will lose some precision. \n",
    "\n",
    "`weights`: Pick how you want to weight all points in each neighborhood. There are two typical ways: `'uniform'` or `'distance'`. Uniform is equal weighting. Distance is weighted by the distance from the point. \n",
    "\n",
    "- `callable` : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
    "\n",
    "`metric`: The distance metric used to search for neighbors. The default is euclidean.\n",
    "\n",
    "`add_indicator`: This will add a dummy feature 0 or 1 if the value was imputed, similar to `add_indicatorbool`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "imputer.fit(X_train_r)\n",
    "X_train_k = imputer.transform(X_train_r)\n",
    "X_test_k = imputer.transform(X_test_r)\n",
    "\n",
    "y_train_k = y_train_r.copy()\n",
    "y_test_k = y_test_r.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Drop Null Model\n",
    "clf_n = RandomForestRegressor(random_state=0)\n",
    "clf_n.fit(X_train_d, y_train_d)\n",
    "pred_dropna = clf_n.predict(X_test_d)\n",
    "\n",
    "# Mean Imputation Model\n",
    "clf_m = RandomForestRegressor(random_state=0)\n",
    "clf_m.fit(X_train_m, y_train_m)\n",
    "pred_m = clf_m.predict(X_test_m)\n",
    "\n",
    "# Regression Imputation\n",
    "clf_r = RandomForestRegressor(random_state=0)\n",
    "clf_r.fit(X_train_r, y_train_r)\n",
    "pred_r = clf_r.predict(X_test_r)\n",
    "\n",
    "#Nearest Neighbor Imputation\n",
    "clf_n = RandomForestRegressor(random_state=0)\n",
    "clf_n.fit(X_train_k, y_train_k)\n",
    "pred_k = clf_n.predict(X_test_k)\n",
    "\n",
    "\n",
    "print('Drop Null MAE Score: %.3f' % mean_absolute_error(y_test_d,pred_dropna))\n",
    "print('Mean Impute MAE Score: %.3f' % mean_absolute_error(y_test_m,pred_m))\n",
    "print('Regression MAE Score: %.3f '% mean_absolute_error(y_test_r,pred_r))\n",
    "print('Nearest Neighbor MAE Score: %.3f'% mean_absolute_error(y_test_k,pred_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, you learned about a variety of missing value imputation techniques, ranging from simple to more complex. We went over:\n",
    "\n",
    "- Dropping Nulls\n",
    "\n",
    "- Mean/Median/Mode Imputation\n",
    "\n",
    "- Regression Imputation (linear and forests)\n",
    "\n",
    "- Nearest Neighbor Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
